%!TEX root = ../report.tex

\chapter{Introduction}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Motivation}

Manipulation is an important functionality for applied robotics. Manipulating objects involves moving an end effector
to the desired object's location and using this end effector to interact with the manipulated object to execute a
specific task. The task can be simply moving the object to another location or can require more complicated maneuvers
of the object (i.e. moving a handle to open doors or moving a bottle to pour water). Traditionally the end effector in
the industry is a two-fingered gripper. Any object movement, in this case, requires manipulating the whole arm, which is
effective for transferring objects over large motion ranges but can be intractable for tasks requiring more precise
movements. The recent vacuum based effectors face similar problems in object manipulation. To handle finer motions, the
common solutions in the industry are either using custom designed end-effector or multi-finger robot hands. The problem
of robotic grasping typically refers to the use of grippers and multi-finger end effectors to manipulate objects. 70
years after the conception of the first robot arm, a general solution to finding a suitable grasp for objects is still a
challenging problem and an area of active research.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Use Case}

\picHereWidth{robocup_typical_objects}
             {Typical objects in the Robocup@Home competition \cite{robocupRulebook2018}.}
             {fig:robocup_objects}{0.9\textwidth}

This project focuses on the use cases of robotic grasping in the
\footnoteHref{http://www.robocupathome.org/}{Robocup @Home} league. The tasks in this competition are designed to
evaluate the performance of autonomous robots in service robotic applications in a domestic environment. The objects to
be manipulated are ones that can be found in a typical household setting. Some examples of such objects can be seen in
figure \ref{fig:robocup_objects}. These objects can be placed on tables, shelves or in a dishwasher, whose locations
can be anywhere in a simulated apartment. Grasping tasks in such an environment is challenging than because of various
factors, including the variety of object shapes, the uncertainty of the robot manipulator and objects' locations,
and the many noise/disturbance sources which can interfere with the robot's perceptual sensors such as lighting
condition or object occlusion.

The platform used for the project's experiments is the robot chosen for the standard platform for the Robocup@Home
league, the
\footnoteHref{https://www.toyota-global.com/innovation/partner\_robot/robot/\#link02}{Toyota Human Support Robot (HSR)}
\cite{robocupRulebook2018}. The robot is equipped with an RGB-D sensor
(\footnoteHref{https://www.asus.com/3D-Sensor/Xtion\_PRO\_LIVE/}{Xtion PRO LIVE}), stereo camera and a wide-angle camera
on the robot head, as well as a wide angle camera mounted on the two-finger gripper. The gripper also has a
potentiometer and a force sensor.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{An overview of robotic grasping research} \label{sub:overview}

\picHereWidth{bohg14-grasp_synthesis_mind_map}
             {Aspects which may influence generation of grasp hypotheses \cite{Bohg2014}.}
             {fig:grasp_synthesis_mind_map}{\textwidth}
Synthesizing an optimal grasp from perceptual data is a challenging problem and is frequently addressed in robotic
research, resulting in a myriad of approaches. Sahbani et al. \cite{Sahbani2012} classify grasp synthesis into
analytical and empirical approaches. Analytical methods consider mechanical properties of the contact points between
the gripper's fingers and an object \cite{Roa2015, Sahbani2012, Shimoga1996}, namely:
\begin{itemize}
    \item \emph{Disturbance resistance}: the ability of the grasp to resist disturbances when the object is immobile,
    either by form-closure (finger positions) or force-closure (forces applied by fingers).
    \item \emph{Dexterity}: the ability of the robot hand to move the object to perform a specified task, or in any
    direction if no task is specified.
    \item \emph{Equilibrium}: the combined forces and torques applied to the object is null.
    \item \emph{Stability}: any displacement of an object caused by a disturbance will self-correct over time.
\end{itemize}
Instead of analyzing mechanical properties, empirical approaches rely on some form of grasp experience to synthesize
candidates. Sahbani et al. \cite{Sahbani2012} group empirical approaches based on whether they focus on observing humans
or objects. The first group of methods teaches a robotic system to observe a human operator via different forms of
descriptors, then to reproduce the same grasp. These techniques are also known as learning by demonstration. Methods
focusing on object observation generally learn the association between object characteristics and gripper
configurations. The survey by Bohg et al. \cite{Bohg2014} argue instead to classify data-driven methods based on how
much information is assumed about the query object, specifically:
\begin{itemize}
    \item Approaches dealing with \emph{known objects} rely on a grasp experience database which contains suitable
    grasps for each encountered object. These approaches, therefore, focus on object recognition and pose estimation.
    \item Approaches for \emph{familiar objects} focus on finding a similarity metric and an object representation,
    from low (i.e. shape, color, texture) to high (i.e. category) levels, to match query objects with encountered
    objects.
    \item Approaches for \emph{unknown objects} identify local or global features from sensory data to for generating
    and evaluating grasp candidates.
\end{itemize}
The authors argue that this classification can better capture the diversity of empirical approaches as well as
the importance of perception in the process. In addition to the above classification, Bohg et al. \cite{Bohg2014}
also identify principal factors that may influence a grasp hypothesis, as shown in the mind map in figure
\ref{fig:grasp_synthesis_mind_map}.

Analytical approaches to synthesizing grasps generally rely on knowledge of the object, the gripper model and the
contact location of the fingers. This information is often inaccurate or unavailable in the real environment
because of noisy sensors as well as imprecise manipulator/gripper actuation. Indeed, analytical methods have been
shown to be unreliable in synthesizing stable grasps when applied on real robots
\cite{Kappler2015,Rubert2017,WeiszAllen2012}. Empirical approaches, however, as with other supervised machine
learning methods, demand labeled data. Generating a sufficiently large grasp experience knowledge base is often
time-consuming and expensive, while grasp simulation may not be close enough to the real world.

Data augmentation, the process of generating new samples by transforming real data, and data synthesis are popular
solutions to supplementing limited training data \cite{Fawzi2016,Shrivastava2017}, especially when applying deep
learning methods to solve image recognition and detection tasks. As grasp synthesis algorithms need 3D information
synthesizing the gripper configuration, RGB-D is often preferred over images as training data. The research in
\cite{Eitel2015,Gupta2014RGBDFeatures} proposes approaches to augmenting RGB-D data, whereas Mahler et al.
\cite{mahler2017} generates synthetic data to train a grasp quality predictor.

In order to leverage the successes of deep learning for various perception and grasping tasks, which are in general
supervised techniques, this project shall focus on data generation and augmentation for empirical approaches to grasp
synthesis using labeled data.

\todo{layout of the report}
